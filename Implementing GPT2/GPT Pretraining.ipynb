{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625295c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.1\n",
      "numpy version: 2.1.3\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.1\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29dbb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpt import GPTModel\n",
    "GPT_CONFIG_124M={\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":256,\n",
    "    \"emb_dim\":468,\n",
    "    \"n_heads\":12,\n",
    "    \"n_layers\":12,\n",
    "    \"drop_rate\":0.1,\n",
    "    \"qkv_bias\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44766ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 468)\n",
       "  (pos_emb): Embedding(256, 468)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=468, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95945c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from gpt import generate_text_simple\n",
    "def text_to_token_ids(text,tokenizer):\n",
    "    encoded=tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor=torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "def token_ids_to_text(token_ids,tokenizer):\n",
    "    flat=token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc87fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context=\"Every effort moves you\"\n",
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids=generate_text_simple(model=model,idx=text_to_token_ids(start_context,tokenizer),max_new_tokens=10,context_size=GPT_CONFIG_124M['context_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d372e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " Every effort moves you behaves Nolan contact contributingchair guessesimil YellowArthur university\n"
     ]
    }
   ],
   "source": [
    "print(\"output text:\\n\", token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae780f4",
   "metadata": {},
   "source": [
    "# Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9feeed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) # \"really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c0404e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits=model(inputs)\n",
    "probas=torch.softmax(logits,dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ee5299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[37259],\n",
      "         [28694],\n",
      "         [33906]],\n",
      "\n",
      "        [[36750],\n",
      "         [43005],\n",
      "         [13144]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids=torch.argmax(probas,dim=-1,keepdim=True)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a822b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  rainy009Va\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0],tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b785afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([4.9556e-06, 8.7060e-06, 2.5850e-05])\n",
      "Text 2: tensor([9.7422e-06, 3.1885e-05, 3.1743e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx=0\n",
    "target_probas_1=probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(\"Text 1:\",target_probas_1)\n",
    "text_idx=1\n",
    "target_probas_2=probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(\"Text 2:\",target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bdabbe",
   "metadata": {},
   "source": [
    "compute logarithm of all token probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcf6f4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-12.2150, -11.6515, -10.5632, -11.5390, -10.3534, -10.3578])\n"
     ]
    }
   ],
   "source": [
    "log_probas=torch.log(torch.cat((target_probas_1,target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b257c80",
   "metadata": {},
   "source": [
    "calculate the average probabiity for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e29f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.1133)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas=torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7ba75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1133)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas=avg_log_probas*-1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d103113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logitsa shape torch.Size([2, 3, 50257])\n",
      "targets shape torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"logitsa shape\",logits.shape)\n",
    "print(\"targets shape\",targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca0b45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat=logits.flatten(0,1)\n",
    "targets_flat=targets.flatten()\n",
    "print(\"Flattened logits:\",logits_flat.shape)\n",
    "print(\"Flattened targets:\",targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a62500d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1133)\n"
     ]
    }
   ],
   "source": [
    "#defining the loss functions\n",
    "loss=torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de693866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(67058.9297)\n"
     ]
    }
   ],
   "source": [
    "#perplexity of the model\n",
    "perplexity=torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c71648",
   "metadata": {},
   "source": [
    "# Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad61091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5c63576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "808de376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b21d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters=len(text_data)\n",
    "total_tokens=len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\",total_characters)\n",
    "print(\"tokens:\",total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fb8cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio=0.90\n",
    "split_idx=int(train_ratio*len(text_data))\n",
    "train_data=text_data[:split_idx]\n",
    "val_data=text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17cdcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader=create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader=create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed2844be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6425978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d9181a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens=0\n",
    "for input_batch,target_batch in train_loader:\n",
    "    train_tokens+=input_batch.numel()\n",
    "val_tokens=0\n",
    "for input_batch,target_batch in val_loader:\n",
    "    val_tokens+=input_batch.numel()\n",
    "print(\"Training tokens:\",train_tokens)\n",
    "print(\"Validation tokens:\",val_tokens)\n",
    "print(\"All tokens:\",train_tokens+val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b278e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch,target_batch=input_batch.to(device),target_batch.to(device)\n",
    "    logits=model(input_batch)\n",
    "    loss=torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
    "    return loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc15486d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5f12109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7469d4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.accelerator.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6a86ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.001415040757921\n",
      "Validation loss: 10.9550199508667\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss=calc_loss_loader(train_loader,model,device)\n",
    "    val_loss=calc_loss_loader(val_loader,model,device)\n",
    "print(\"Training loss:\",train_loss)\n",
    "print(\"Validation loss:\",val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e88068",
   "metadata": {},
   "source": [
    "# Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d82e2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc688e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4d94ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.398, Val loss 10.360\n",
      "Ep 1 (Step 000005): Train loss 8.895, Val loss 9.058\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m optimizer=torch.optim.AdamW(model.parameters(),lr=\u001b[32m0.0004\u001b[39m,weight_decay=\u001b[32m0.1\u001b[39m)\n\u001b[32m      8\u001b[39m num_epochs=\u001b[32m10\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_losses, val_losses, tokens_seen = \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvery effort moves you\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m end_time=time.time()\n\u001b[32m     15\u001b[39m execution_time_minutes=(end_time-start_time)/\u001b[32m60\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain_model_simple\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Optional evaluation step\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_step % eval_freq == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     train_loss, val_loss = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     train_losses.append(train_loss)\n\u001b[32m     24\u001b[39m     val_losses.append(val_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, train_loader, val_loader, device, eval_iter)\u001b[39m\n\u001b[32m     38\u001b[39m model.eval()\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     train_loss = \u001b[43mcalc_loss_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n\u001b[32m     42\u001b[39m model.train()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mcalc_loss_loader\u001b[39m\u001b[34m(data_loader, model, device, num_batches)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (input_batch, target_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i < num_batches:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         loss = \u001b[43mcalc_loss_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m         total_loss += loss.item()\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcalc_loss_batch\u001b[39m\u001b[34m(input_batch, target_batch, model, device)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalc_loss_batch\u001b[39m(input_batch,target_batch,model,device):\n\u001b[32m      2\u001b[39m     input_batch,target_batch=input_batch.to(device),target_batch.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     logits=\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     loss=torch.nn.functional.cross_entropy(logits.flatten(\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m),target_batch.flatten())\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\Implementing GPT2\\gpt.py:98\u001b[39m, in \u001b[36mGPTModel.forward\u001b[39m\u001b[34m(self, in_idx)\u001b[39m\n\u001b[32m     96\u001b[39m x = tok_embeds + pos_embeds  \u001b[38;5;66;03m# Shape [batch_size, num_tokens, emb_size]\u001b[39;00m\n\u001b[32m     97\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_emb(x)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrf_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_norm(x)\n\u001b[32m    100\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.out_head(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\Implementing GPT2\\gpt.py:72\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     70\u001b[39m shortcut = x\n\u001b[32m     71\u001b[39m x = \u001b[38;5;28mself\u001b[39m.norm2(x)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_shortcut(x)\n\u001b[32m     74\u001b[39m x = x + shortcut  \u001b[38;5;66;03m# Add the original input back\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\Implementing GPT2\\gpt.py:43\u001b[39m, in \u001b[36mFeedForward.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\Implementing GPT2\\gpt.py:27\u001b[39m, in \u001b[36mGELU.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.5\u001b[39m * x * (\u001b[32m1\u001b[39m + \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.044715\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#now training the LLM\n",
    "import time\n",
    "start_time=time.time()\n",
    "torch.manual_seed(123)\n",
    "model=GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay=0.1)\n",
    "num_epochs=10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "end_time=time.time()\n",
    "execution_time_minutes=(end_time-start_time)/60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99000d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9518f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a79bca",
   "metadata": {},
   "source": [
    "# Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fcd20c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: \n",
      " Every effort moves you know,\" was not that my hostess was \"I was a that point I had been of the fact that one of the\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids=generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]   \n",
    ")\n",
    "print(\"Output text: \\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee2b83",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "924fc941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 468)\n",
       "  (pos_emb): Embedding(256, 468)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=468, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d01d6637",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m torch.save({\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m\"\u001b[39m: model.state_dict(),\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moptimizer_state_dict\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43moptimizer\u001b[49m.state_dict(),\n\u001b[32m      4\u001b[39m },\n\u001b[32m      5\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mmodel_and_optimizer.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "},\n",
    "\"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8a908",
   "metadata": {},
   "source": [
    "# Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d15cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab={\n",
    "    \"closer\":0,\n",
    "    \"every\":1,\n",
    "    \"effort\":2,\n",
    "    \"forward\":3,\n",
    "    \"inches\":4,\n",
    "    \"moves\":5,\n",
    "    \"pizza\":6,\n",
    "    \"toward\":7,\n",
    "    \"you\":8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf7e6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_vocab={v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9317f339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'closer',\n",
       " 1: 'every',\n",
       " 2: 'effort',\n",
       " 3: 'forward',\n",
       " 4: 'inches',\n",
       " 5: 'moves',\n",
       " 6: 'pizza',\n",
       " 7: 'toward',\n",
       " 8: 'you'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0bd2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afcad0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f3e7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id=torch.multinomial(probas,num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5435209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample=[torch.multinomial(probas,num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i,freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be6d8797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "621b1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits,temperature):\n",
    "    scaled_logits=logits/temperature\n",
    "    return torch.softmax(scaled_logits,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76f93337",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures=[1,0.1,5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c077733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5eced6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=torch.arange(len(vocab))\n",
    "bar_width=0.15\n",
    "fig,ax=plt.subplots(figsize=(5,3))\n",
    "for i,T in enumerate(temperatures):\n",
    "    rects=ax.bar(x+i*bar_width,scaled_probas[i],bar_width,label=f'Temperature={T}')\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(),rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperatures-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e3f6a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a237c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef3310",
   "metadata": {},
   "source": [
    "# Top K sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "053b118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "top pos: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k=3\n",
    "top_logits,top_pos=torch.topk(next_token_logits,top_k)\n",
    "print(\"top logits:\",top_logits)\n",
    "print(\"top pos:\",top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "016ce51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits=torch.where(\n",
    "    condition=next_token_logits<top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d5349bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas=torch.softmax(new_logits,dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd36e7a",
   "metadata": {},
   "source": [
    "# Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6ecf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2799ef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was not that my own picture his! \"I must up-\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697b2a0",
   "metadata": {},
   "source": [
    "# Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0910eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"gpt2-small-124M.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42fbf72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87a5c7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to gpt2-small-124M.pth\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e793de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72afb7a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emb_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m gpt = \u001b[43mGPTModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_CONFIG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m gpt.load_state_dict(torch.load(file_name, weights_only=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m      3\u001b[39m gpt.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\LLMS FROM SCRATCH\\Implementing GPT2\\gpt.py:82\u001b[39m, in \u001b[36mGPTModel.__init__\u001b[39m\u001b[34m(self, cfg)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg):\n\u001b[32m     81\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28mself\u001b[39m.tok_emb = nn.Embedding(cfg[\u001b[33m\"\u001b[39m\u001b[33mvocab_size\u001b[39m\u001b[33m\"\u001b[39m], \u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43memb_dim\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m.pos_emb = nn.Embedding(cfg[\u001b[33m\"\u001b[39m\u001b[33mcontext_length\u001b[39m\u001b[33m\"\u001b[39m], cfg[\u001b[33m\"\u001b[39m\u001b[33memb_dim\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mself\u001b[39m.drop_emb = nn.Dropout(cfg[\u001b[33m\"\u001b[39m\u001b[33mdrop_rate\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'emb_dim'"
     ]
    }
   ],
   "source": [
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a4a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6fcada06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 21.9kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 687kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 34.4kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [07:29<00:00, 1.11MiB/s]   \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 1.72MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 383kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 452kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings,params=download_and_load_gpt2(model_size=\"124M\",models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "537e4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\",settings)\n",
    "print(\"Parameter dictionary keys:\",params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a38f7f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token ebedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token ebedding weight tensor dimensions:\",params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9fa6d059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c9c035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0397b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "57b54a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d6970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
