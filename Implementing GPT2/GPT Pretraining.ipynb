{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625295c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.3\n",
      "numpy version: 2.1.3\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.0\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29dbb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpt import GPTModel\n",
    "GPT_CONFIG_124M={\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":256,\n",
    "    \"emb_dim\":468,\n",
    "    \"n_heads\":12,\n",
    "    \"n_layers\":12,\n",
    "    \"drop_rate\":0.1,\n",
    "    \"qkv_bias\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44766ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 468)\n",
       "  (pos_emb): Embedding(256, 468)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_key): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (W_value): Linear(in_features=468, out_features=468, bias=False)\n",
       "        (out_proj): Linear(in_features=468, out_features=468, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=468, out_features=1872, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1872, out_features=468, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=468, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95945c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from gpt import generate_text_simple\n",
    "def text_to_token_ids(text,tokenizer):\n",
    "    encoded=tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor=torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "def token_ids_to_text(token_ids,tokenizer):\n",
    "    flat=token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc87fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context=\"Every effort moves you\"\n",
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids=generate_text_simple(model=model,idx=text_to_token_ids(start_context,tokenizer),max_new_tokens=10,context_size=GPT_CONFIG_124M['context_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4d372e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " Every effort moves you behaves Nolan contact contributingchair guessesimil YellowArthur university\n"
     ]
    }
   ],
   "source": [
    "print(\"output text:\\n\", token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae780f4",
   "metadata": {},
   "source": [
    "# Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9feeed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) # \"really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c0404e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits=model(inputs)\n",
    "probas=torch.softmax(logits,dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ee5299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[37259],\n",
      "         [28694],\n",
      "         [33906]],\n",
      "\n",
      "        [[36750],\n",
      "         [43005],\n",
      "         [13144]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids=torch.argmax(probas,dim=-1,keepdim=True)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a822b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  rainy009Va\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0],tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b785afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([4.9556e-06, 8.7060e-06, 2.5850e-05])\n",
      "Text 2: tensor([9.7422e-06, 3.1885e-05, 3.1743e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx=0\n",
    "target_probas_1=probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(\"Text 1:\",target_probas_1)\n",
    "text_idx=1\n",
    "target_probas_2=probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(\"Text 2:\",target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bdabbe",
   "metadata": {},
   "source": [
    "compute logarithm of all token probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcf6f4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-12.2150, -11.6515, -10.5632, -11.5390, -10.3534, -10.3578])\n"
     ]
    }
   ],
   "source": [
    "log_probas=torch.log(torch.cat((target_probas_1,target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b257c80",
   "metadata": {},
   "source": [
    "calculate the average probabiity for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46e29f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.1133)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas=torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7ba75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1133)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas=avg_log_probas*-1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d103113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logitsa shape torch.Size([2, 3, 50257])\n",
      "targets shape torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"logitsa shape\",logits.shape)\n",
    "print(\"targets shape\",targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0b45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat=logits.flatten(0,1)\n",
    "targets_flat=targets.flatten()\n",
    "print(\"Flattened logits:\",logits_flat.shape)\n",
    "print(\"Flattened targets:\",targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a62500d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1133)\n"
     ]
    }
   ],
   "source": [
    "#defining the loss functions\n",
    "loss=torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de693866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(67058.9297)\n"
     ]
    }
   ],
   "source": [
    "#perplexity of the model\n",
    "perplexity=torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c71648",
   "metadata": {},
   "source": [
    "# Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad61091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5c63576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "808de376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b21d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters=len(text_data)\n",
    "total_tokens=len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\",total_characters)\n",
    "print(\"tokens:\",total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fb8cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c39a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio=0.90\n",
    "split_idx=int(train_ratio*len(text_data))\n",
    "train_data=text_data[:split_idx]\n",
    "val_data=text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17cdcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader=create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader=create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed2844be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6425978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d9181a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens=0\n",
    "for input_batch,target_batch in train_loader:\n",
    "    train_tokens+=input_batch.numel()\n",
    "val_tokens=0\n",
    "for input_batch,target_batch in val_loader:\n",
    "    val_tokens+=input_batch.numel()\n",
    "print(\"Training tokens:\",train_tokens)\n",
    "print(\"Validation tokens:\",val_tokens)\n",
    "print(\"All tokens:\",train_tokens+val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b278e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch,target_batch=input_batch.to(device),target_batch.to(device)\n",
    "    logits=model(input_batch)\n",
    "    loss=torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
    "    return loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5f12109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6a86ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.001415040757921\n",
      "Validation loss: 10.9550199508667\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss=calc_loss_loader(train_loader,model,device)\n",
    "    val_loss=calc_loss_loader(val_loader,model,device)\n",
    "print(\"Training loss:\",train_loss)\n",
    "print(\"Validation loss:\",val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e2e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
